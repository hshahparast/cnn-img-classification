{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will be using the CNN network for an image classification problem, using CIFAR10 as a dataset.\n",
        "\n",
        "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. \n"
      ],
      "metadata": {
        "id": "6barr3AhIqzU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5O58ZTGTYzOT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as func\n",
        "import torch.optim as opt\n",
        "import torch.utils.data as tud\n",
        "import torchvision\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining transformation\n",
        "Data augmentation"
      ],
      "metadata": {
        "id": "QN9BPvteOXE7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "-TV3qR3HZW_u"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "transTrain = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=(0.5, 0.5, 0.5),std=(0.5, 0.5, 0.5)),\n",
        "                                transforms.RandomHorizontalFlip(),transforms.RandomRotation(20) ])\n",
        "transTest = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=(0.5, 0.5, 0.5),std=(0.5, 0.5, 0.5))])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets\n",
        "Loading the CIFAR10 dataset with transformations which are defined above\n",
        "seperating the train dataset into train and validation."
      ],
      "metadata": {
        "id": "0tKam6MJODCn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DziFzkSnec9u",
        "outputId": "3f479652-a24e-4d96-e475-dd8e565696b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "batchSize = 50  #the number of samples in a batch for training\n",
        "valPer = 0.1    #Validation percentage\n",
        "\n",
        "trainData = datasets.CIFAR10('data/train',download=True,train=True,transform=transTrain)  # Creating Train dataset\n",
        "testData = datasets.CIFAR10('data/test',download=True,train=False,transform=transTrain)   # Creating Test dataset\n",
        "\n",
        "\n",
        "trainSize = len(trainData)\n",
        "idxs = list(range(trainSize))\n",
        "np.random.shuffle(idxs)\n",
        "spl = int(np.floor(valPer * trainSize))          #split the dataset to train and validation sets\n",
        "trainIdxs, valIdxs = idxs[spl:], idxs[:spl]\n",
        "\n",
        "trainSamp = SubsetRandomSampler(trainIdxs)\n",
        "valSamp = SubsetRandomSampler(valIdxs)\n",
        "\n",
        "trainLoader = tud.DataLoader(trainData,batch_size=batchSize,sampler=trainSamp,num_workers=0)\n",
        "valLoader = tud.DataLoader(trainData,batch_size=batchSize,sampler=valSamp,num_workers=0)\n",
        "testLoader = tud.DataLoader(testData,batch_size=batchSize,num_workers=0,shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the CNN architecture:\n",
        " \n",
        "*   3 convolutional layer\n",
        "*   relu function \n",
        "*   maxpooling after each convolutional layer\n",
        "*   dropout to avoid overfitting "
      ],
      "metadata": {
        "id": "O3Nbt6r5NkH-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_hjOHRoIuHiR"
      },
      "outputs": [],
      "source": [
        "#Defining the cnn network\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(CNN,self).__init__()\n",
        "      self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
        "      self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
        "      self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "      self.fc1 = nn.Linear(64 * 4 * 4, 500)\n",
        "      self.fc2 = nn.Linear(500, 10)\n",
        "      self.maxPool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "      self.dropout = nn.Dropout(0.25)\n",
        "      self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self,x):\n",
        "      out = self.maxPool(func.relu(self.conv1(x)))\n",
        "      out = self.maxPool(func.relu(self.conv2(out)))\n",
        "      out = self.maxPool(func.relu(self.conv3(out)))\n",
        "      out = out.view(-1, 64 * 4 * 4)\n",
        "      out = self.dropout(out)\n",
        "      out = func.relu(self.fc1(out))\n",
        "      out = self.dropout(out)\n",
        "      out = self.fc2(out)\n",
        "      return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the CNN Network:\n",
        "The error on train and validation sets are decreased over time. we save the network with minimum loss and use it later in prediction."
      ],
      "metadata": {
        "id": "jQkBKOrqNKFA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIr7G7pn8AXd",
        "outputId": "28366eba-c4e5-43b6-804e-e878c0f0a7ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch no 1 , Loss: 1.7765\n",
            "Validation loss: 1.4290\n",
            "Epoch no 2 , Loss: 1.3638\n",
            "Validation loss: 1.2198\n",
            "Epoch no 3 , Loss: 1.2202\n",
            "Validation loss: 1.0970\n",
            "Epoch no 4 , Loss: 1.1256\n",
            "Validation loss: 1.0324\n",
            "Epoch no 5 , Loss: 1.0645\n",
            "Validation loss: 0.9647\n",
            "Epoch no 6 , Loss: 1.0078\n",
            "Validation loss: 0.8845\n",
            "Epoch no 7 , Loss: 0.9689\n",
            "Validation loss: 0.8696\n",
            "Epoch no 8 , Loss: 0.9372\n",
            "Validation loss: 0.8513\n",
            "Epoch no 9 , Loss: 0.9132\n",
            "Validation loss: 0.8165\n",
            "Epoch no 10 , Loss: 0.8884\n",
            "Epoch no 11 , Loss: 0.8791\n",
            "Validation loss: 0.7915\n",
            "Epoch no 12 , Loss: 0.8537\n",
            "Epoch no 13 , Loss: 0.8365\n",
            "Validation loss: 0.7843\n",
            "Epoch no 14 , Loss: 0.8197\n",
            "Validation loss: 0.7803\n",
            "Epoch no 15 , Loss: 0.8094\n",
            "Validation loss: 0.7682\n",
            "Epoch no 16 , Loss: 0.7991\n",
            "Epoch no 17 , Loss: 0.7830\n",
            "Epoch no 18 , Loss: 0.7850\n",
            "Validation loss: 0.7314\n",
            "Epoch no 19 , Loss: 0.7705\n",
            "Validation loss: 0.7222\n",
            "Epoch no 20 , Loss: 0.7651\n"
          ]
        }
      ],
      "source": [
        "#Training the model\n",
        "import torch.optim as optim\n",
        "\n",
        "cnnNet = CNN()\n",
        "cnnNet.to(device)\n",
        "criterion = nn.CrossEntropyLoss()   # Settin Loss function with criterion\n",
        "lr = 0.01 #learning rate\n",
        "optimizer = optim.SGD(cnnNet.parameters(), lr=lr, momentum = 0.9)\n",
        "\n",
        "nepc = 20 # number of epochs\n",
        "\n",
        "\n",
        "desiredLoss = 0.001\n",
        "minLoss = np.Inf\n",
        "\n",
        "for epc in range(1,nepc+1):\n",
        "    trainLoss = 0\n",
        "    cnnNet.train()\n",
        "    #-----------Training\n",
        "    for images, labels in trainLoader: \n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      pred = cnnNet(images)\n",
        "      loss = criterion(pred, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      trainLoss += loss.item()\n",
        "    trainLoss = trainLoss/len(trainLoader)\n",
        "    print('Epoch no {} , Loss: {:.4f}'.format(epc, trainLoss))\n",
        "   \n",
        "    #-----------Validation\n",
        "    cnnNet.eval()\n",
        "    valLoss = 0\n",
        "    valLoss2 = 0\n",
        "    for images,labels in valLoader:\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      pred = cnnNet(images)\n",
        "      loss = criterion(pred, labels)\n",
        "      valLoss += loss.item()\n",
        "\n",
        "    valLoss = valLoss/len(valLoader)\n",
        "    if valLoss < minLoss:  #saving the model with minimum loss\n",
        "      torch.save(cnnNet.state_dict(), 'cnnNet')\n",
        "      minLoss = valLoss\n",
        "      print('Validation loss: {:.4f}'.format(valLoss))\n",
        "    if valLoss < desiredLoss:\n",
        "      break\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnnNet.load_state_dict(torch.load('cnnNet'))  #Loading the best model, with minimum error"
      ],
      "metadata": {
        "id": "tqNlMA_rHPWZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56eea7d8-5062-4ffa-d57b-6ba6ce2ef31c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testLoss = 0\n",
        "correct = 0\n",
        "cnnNet.eval()\n",
        "total = 0\n",
        "for images,labels in testLoader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    pred = cnnNet(images)\n",
        "    loss = criterion(pred, labels)\n",
        "    testLoss += loss.item()*images.size(0)\n",
        "    total += labels.size(0)\n",
        "    _, pred = torch.max(pred, 1)\n",
        "    correct += (pred == labels).sum().item()\n",
        "testLoss = testLoss/len(testLoader)\n",
        "\n",
        "print('The final accuracy of the network on test images: {:.4f}'.format(correct/total*100))\n"
      ],
      "metadata": {
        "id": "iLvWgKnExwmZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1a249a5-cd45-4058-ff00-09b5e6a5837a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The final accuracy of the network on test images: 74.3300\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyNSkVkLB2yUkZHmDqE8BhEx"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}